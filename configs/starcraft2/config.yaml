project_name: scaling
group_name: staleness
algorithm_name: rmappo
env_name: StarCraft2
map_name: 3s5z_vs_3s6z
user_name: garrett4wade
experiment_name: baseline
benchmark: false
cuda: true
cuda_deterministic: true
seed: 2
no_summary: false
use_wandb: true
use_eval: true
use_render: false

num_env_steps: 400000000
train_for_env_steps: 400000000
train_for_seconds: 10000000000000000
model_dir: null
save_dir: './models'
summary_dir: './logs'

# system parameters
num_tasks_per_node: 1
num_actors: 128
actor_group_size: 1
envs_per_actor: 2
num_policy_workers: 4
qsize: 6
min_num_requests: -1

ddp_init_methods:
  - tcp://10.0.4.6:6666
task_dispatcher_addr: tcp://10.0.4.6:8887
task_result_addr: tcp://10.0.4.6:8886
model_weights_addrs:  # every learner has a model_weights_addr and len(model_weights_adddrs) == num_policies == num_leraners
  - tcp://10.0.4.6:8889
seg_addrs:  # every worker node has seg_addrs connecting to all learners
  - - tcp://10.0.4.6:12346

num_reanalyzers_per_trainer: 1
num_value_tracers_per_trainer: 1
slots_per_update: 64
episode_length: 400

learner_config:
  "0":
    "0": 0
    # "1": 0
    # "2": 0
    # "3": 0
num_policies: 1
policy2agents:
  "0":
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    # - 8
    # - 9
    # - 10
    # - 11
    # - 12
    # - 13
    # - 14
    # - 15
    # - 16
    # - 17
    # - 18
    # - 19
    # - 20
    # - 21
    # - 22
    # - 23
    # - 24
    # - 25
    # - 26

# fixed system parameters
num_splits: 2
stats_avg: 100
set_workers_cpu_affinity: true
force_envs_single_thread: true
default_niceness: 0
eval_episodes: 32
eval_interval: 100
log_interval: 20
n_training_threads: 1
reset_timeout_seconds: 60
actor_worker_gpus: 0

# algorithm parameters
data_chunk_length: 10
hidden_size: 64
layer_N: 1
rec_n: 1
sample_reuse: 5
num_mini_batch: 1
lr: 0.0005
max_grad_norm: 10.0
entropy_coef: 0.01
gamma: 0.99
gae_lambda: 0.95
gain: 0.01
value_coef: 1.0
weight_decay: 0
opti_eps: 1.0e-05
clip_param: 0.2
huber_delta: 10.0

# render parameters
ifi: 0.1
render_episodes: 5
save_gifs: false
save_interval: 1

# tricks
share_policy: true
use_reanalyze: false
use_fct_masks: true
use_feature_normalization: true
use_gae: true
use_huber_loss: true
use_linear_lr_decay: false
use_max_grad_norm: true
use_orthogonal: true
use_popart: true
use_proper_time_limits: false
use_ReLU: true
use_advantage_normalization: true
use_centralized_V: true
use_clipped_value_loss: true
no_value_active_masks: true
no_policy_active_masks: false

# some fixed tricks
add_agent_id: false
use_obs_instead_of_state: false
add_distance_state: false
add_enemy_action_state: false
add_local_obs: false
add_move_state: false
add_visible_state: false
add_xy_state: false
use_stacked_frames: false
stacked_frames: 1
use_state_agent: true
use_mustalive: true
add_center_xy: true

# setup configs, use absolute dir
cwd: "/workspace/workspace/scaling_marl"
trainer_dir: "run_learner_node.py"
worker_dir: "run_worker_node_on_smac.py"
monitor_dir: "run_monitor.py"
log_dir: "log/"

trainer_logname: "trainer.log"
worker_logname: "worker.log"
monitor_logname: "monitor.log"

# configdir: "configs/starcraft2/config.yaml"
workers: "71"
trainers: "70"
container_name: scaling

# monitor configs
total_rounds: 100000000 # debug
interval: 3
# first node is head
nodes: learner0,worker0
puller_address: "10.0.4.6"
puller_port: 4321

verbose: false
