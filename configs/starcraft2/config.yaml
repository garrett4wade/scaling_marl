project_name: scaling
group_name: wandb_test
algorithm_name: rmappo
env_name: StarCraft2
map_name: 2m_vs_1z
user_name: garrett4wade
experiment_name: test
benchmark: false
cuda: true
cuda_deterministic: true
seed: 1
no_summary: true
use_wandb: true
use_eval: false
use_render: false

num_env_steps: 10000000
train_for_env_steps: 10000000000
train_for_seconds: 500
model_dir: null
save_dir: './models'
summary_dir: './logs'

# system parameters
num_policies: 2
learner_config:
  "0":
    "0": 0
    "1": 1
policy2agents:
  "0":
    - 0
  "1":
    - 1
ddp_init_methods:
  - tcp://10.0.4.57:6666
  - tcp://10.0.4.57:6667
task_dispatcher_addr: tcp://10.0.4.57:8887
task_result_addr: tcp://10.0.4.57:8886
num_tasks_per_node: 4
model_weights_addrs:  # every learner has a model_weights_addr and len(model_weights_adddrs) == num_policies == num_leraners
  - tcp://10.0.4.57:8889
  - tcp://10.0.4.57:8890
seg_addrs:  # every worker node has seg_addrs connecting to all learners
  - - tcp://10.0.4.57:12346
num_actors: 8
actor_group_size: 1
envs_per_actor: 2
min_num_requests: -1
num_policy_workers: 2
slots_per_update: 8
qsize: 12
num_splits: 2
data_chunk_length: 10
episode_length: 400

# fixed system parameters
stats_avg: 100
set_workers_cpu_affinity: true
force_envs_single_thread: true
default_niceness: 0
eval_episodes: 32
eval_interval: 25
log_interval: 20
n_training_threads: 16
reset_timeout_seconds: 60
actor_worker_gpus: 0

# algorithm parameters
hidden_size: 64
layer_N: 1
rec_n: 1
sample_reuse: 5
num_mini_batch: 1
lr: 0.0005
max_grad_norm: 10.0
entropy_coef: 0.01
gamma: 0.99
gae_lambda: 0.95
gain: 0.01
value_coef: 1.0
weight_decay: 0
opti_eps: 1.0e-05
clip_param: 0.2
huber_delta: 10.0

# render parameters
ifi: 0.1
render_episodes: 5
save_gifs: false
save_interval: 1

# tricks
share_policy: true
use_reanalyze: false
use_fct_masks: true
use_feature_normalization: true
use_gae: true
use_huber_loss: true
use_linear_lr_decay: false
use_max_grad_norm: true
use_orthogonal: false
use_popart: true
use_proper_time_limits: false
use_ReLU: true
use_active_masks: true
use_advantage_normalization: true
use_centralized_V: true
use_clipped_value_loss: true

# some fixed tricks
add_agent_id: false
add_center_xy: true
add_distance_state: false
add_enemy_action_state: false
add_local_obs: false
add_move_state: false
add_visible_state: false
add_xy_state: false
use_stacked_frames: false
stacked_frames: 1
use_state_agent: true
use_mustalive: true
use_obs_instead_of_state: false