project_name: hide_and_seek
group_name: reproduce
algorithm_name: rmappo
env_name: HideAndSeek
map_name: HideAndSeek
user_name: chenjy
experiment_name: debug_num_critic1
benchmark: false
cuda: true
cuda_deterministic: true
seed: 1
no_summary: false
use_wandb: true
use_eval: true
use_render: false

# cl
num_critic: 1

num_env_steps: 200.0e+9
train_for_env_steps: 200.0e+9
train_for_seconds: 10000000000000000
model_dir: null
save_dir: './models'
summary_dir: './logs'

# system parameters
num_tasks_per_node: 1
num_actors: 128
actor_group_size: 1
envs_per_actor: 8
num_policy_workers: 4
qsize: 5
min_num_requests: -1

ddp_init_methods:
  - tcp://localhost:6676
task_dispatcher_addr: tcp://localhost:8897
task_result_addr: tcp://localhost:8896
model_weights_addrs:  # every learner has a model_weights_addr and len(model_weights_adddrs) == num_policies == num_leraners
  - tcp://localhost:8899
reset_addrs:
  - tcp://localhost:9000
seg_addrs:  # every worker node has seg_addrs connecting to all learners
  - - tcp://localhost:12366

num_reanalyzers_per_trainer: 1
num_value_tracers_per_trainer: 1
slots_per_update: 480
episode_length: 80

learner_config:
  "0":
    "0": 0

num_policies: 1
policy2agents:
  "0":
    - 0
    - 1
    - 2

# fixed system parameters
num_splits: 2
stats_avg: 100
set_workers_cpu_affinity: true
force_envs_single_thread: true
default_niceness: 0
eval_episodes: 32
eval_interval: 100
log_interval: 100
n_training_threads: 1
reset_timeout_seconds: 60
actor_worker_gpus: 0

# algorithm parameters
data_chunk_length: 10
hidden_size: 256
layer_N: 1
rec_n: 1
sample_reuse: 4
num_mini_batch: 1
lr: 3.0e-4
max_grad_norm: 5.0
entropy_coef: 0.01
gamma: 0.998
gae_lambda: 0.95
gain: 0.01
value_coef: 1.0
weight_decay: 1.0e-6
opti_eps: 1.0e-05
clip_param: 0.2
huber_delta: 10.0

# render parameters
ifi: 0.1
render_episodes: 5
save_gifs: false
save_interval: 1000

# tricks
share_policy: true
use_reanalyze: false
use_fct_masks: true
use_feature_normalization: true
use_gae: true
use_huber_loss: false
use_linear_lr_decay: false
use_max_grad_norm: true
use_orthogonal: true
use_popart: true
use_proper_time_limits: false
use_ReLU: true
use_advantage_normalization: true
use_centralized_V: false
use_clipped_value_loss: false
no_value_active_masks: true
no_policy_active_masks: true

# setup configs, use absolute dir
cwd: "/home/jiayu-ch15/scaling_marl"
trainer_dir: "run_learner_node.py"
worker_dir: "run_worker_node_on_smac.py"
monitor_dir: "run_monitor.py"
log_dir: "log/"

trainer_logname: "trainer.log"
worker_logname: "worker.log"
monitor_logname: "monitor.log"

# configdir: "configs/starcraft2/config.yaml"
workers: "71"
trainers: "70"
container_name: scaling

# monitor configs
total_rounds: 100000000 # debug
interval: 3
# first node is head
nodes: learner0,worker0
puller_address: "localhost"
puller_port: 4321

verbose: false
